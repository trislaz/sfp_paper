\section{Introduction}

Recent advances in slide digitization have led to increased  interest in Artificial Intelligence (AI) applications for histopathology. The development of AI models could help reduce pathologists’ workloads, limit subjectivity and help contributing to medical discoveries. Deep learning models can now match pathologist performance for many tasks: diagnostic, detection of mitoses \citep{veta_assessment_2015}, prediction of gene mutations \citep{coudray_classification_2018, kather_pan-cancer_2020} or genetic signatures \citep{kather_pan-cancer_2020, diao_human-interpretable_2021,lazard_deep_2021}, cancer subtyping \citep{coudray_classification_2018} and more. \\
One of the applications, automated diagnosis from Whole Slide Images (WSIs), induces two main challenges: first, WSIs are very high-resolution and, because of memory constraint, cannot be fed directly into traditional neural networks. Second, expert annotations are laborious to attain, costly and prone to subjectivity. The most popular methods today rely on Multiple Instance Learning (MIL), which frames the problem as a bag classification task. WSIs are split into small workable images (tiles), which are processed separately. Features from each of the individual tiles are extracted and then aggregated to classify the WSI. \\
The extraction of these tiles’ specific representation is crucial to the downstream WSI classification task. One common approach consists of initializing the feature extractor with pre-trained weights on ImageNet, a natural image dataset. This technique allows one to extract generic features that are powerful, but that do not lie within the histopathological domain. Different strategies have been developed to extract these tile encodings taking advantage of the available data and their respective level of supervision. \\
A first strategy aims to learn tile features with full supervision \citep{ehteshami_bejnordi_diagnostic_2017}. To create a supervised dataset, one or several experts manually review tiles and sort them into meaningful classes, preferably related to the downstream task of classifying the WSIs or equivalently perform the semantic segmentation of the WSI. Even though experts' annotations can bring powerful prior knowledge to the model, this technique often requires large quantities of annotations. \\
A second strategy consists of learning tile representations through self-supervision. It leverages the unannotated data by training a convolutional neural network on a pretext task. It has proven its efficacy \citep{saillard_identification_2021, lu_data-efficient_2021} and even its superiority over the fully supervised scheme \citep{dehaene_self-supervision_2020}. However, this approach has a non-negligible computational cost, as training necessitates around 1000 hours of computation on a standard GPU \citep{dehaene_self-supervision_2020}. Moreover, it is not guaranteed that the obtained encodings are most relevant for the prediction task we are trying to solve. \\
Techniques from both sides of the supervision spectrum have proven to bring important benefits for relevant feature extraction. Combining them could allow us to benefit from the best of both worlds. \\
In this work, in addition to proposing a joint-optimization process mixing self, full and weak supervision (Figure \ref{fig:pipeline_summary}), we measure the trade-off in performance between the number of annotations and the computational cost of training a self-supervised model. We thus provide guidelines to train a clinically impactful classifier with a limited budget in expert and/or computational workload. \\

\begin{figure*}[!t]
\centering
\includegraphics[scale=.35]{figures/pipeline_summary.pdf}
\caption{\textbf{Mixed Supervision Process}: \textbf{a)}A self-supervised model (SimCLR) is trained on unlabelled tiles extracted from the slides. Feature extractor and contrastive layer weights are transferred to the joint-optimization architecture \textbf{b)} Joint-optimization model is trained on the labeled tiles of the dataset. The feature extractor weights are transferred to the WS classification model. \textbf{c)} WS classification model is trained on the 1015 whole slide images.}
\label{fig:pipeline_summary}
\end{figure*}


