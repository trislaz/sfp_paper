\section{Related Work}

\paragraph{Mixed Supervision}

Medical data is often limited. For this reason, one might want to take advantage of all the available data even if annotations might not be homogeneous and even though they might be difficult to exploit because multiple levels of supervision are available. For instance, whole slide images are often associated with one global label (weak supervision), they can contain millions of unlabelled tiles (no supervision), but, as a pathologist reviews the slides and performs a diagnostic, it is almost effortless for them to mark the region of interest that signs the corresponding diagnostic (strong supervision). AI applications have usually been dichotomized between supervised and unsupervised methods, spoiling the potential of combining several types of annotations. For this reason, mixing supervision for medical image analysis  has gained interest in recent years \citep{huang_rectifying_2020, li_thoracic_2018, li_hybrid_2021}.
For instance, in \citep{mlynarski_deep_2019} the author showed that combining global labels and local annotations by training in a multi-task setting, the capacities of the model to segment brain tumors on magnetic resonance images were improved.  \\
In \citep{tourniaire_attention-based_2021}, the author introduced a mixed supervision framework for WSI classification powering the CLAM \citep{lu_data-efficient_2021} architecture. They introduced supervision in the CLAMâ€™s clustering task: instead of using pseudo-labels derived from attention weights for each tile, the annotated tiles were used.  In this work, the fully supervised information is injected at the WSI classification step. A mixture of WSI classification loss (weak supervision) and an instance-level classification loss (full-supervision) is optimized while, in contrast, we propose to optimize a combination of a contrastive loss (self-supervision) and an instance-level classification loss (full-supervision). \\
Their approach leads to an improvement of the WSI classification scores and disease localization with the attention score. It is, however, limited by the number of parameters that are concerned with this mixed supervision regime. While our method allows the fine-tuning of the whole feature extractor, the latter approach only fine-tunes a single linear layer downstream the feature extraction. Finally, the annotations used in \citep{tourniaire_attention-based_2021} are exhaustive: for the annotated slides, all the key regions are annotated pixel-wise. The resulting tile-level dataset is therefore bigger than the fully supervised dataset available for the TissueNet challenge.